{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Neural Network (VI) for classification - Distributed Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#\n",
    "#   Licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "#   You may not use this file except in compliance with the License.\n",
    "#   A copy of the License is located at\n",
    "#\n",
    "#       http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#   or in the \"license\" file accompanying this file. This file is distributed\n",
    "#   on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "#   express or implied. See the License for the specific language governing\n",
    "#   permissions and limitations under the License.\n",
    "# ==============================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example follows the same example from [Bayesian Neural Network (VI) for classification](bnn_classification.ipynb), with implementation of Horovod's distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mxfusion as mf\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import mxnet.gluon.nn as nn\n",
    "import mxfusion.components\n",
    "import mxfusion.inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, initialize Horovod with <tt>hvd.init()</tt>. We also want to set the global context to GPU or CPU depends where the code is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import horovod.mxnet as hvd\n",
    "import mxnet as mx\n",
    "hvd.init()\n",
    "mx.context.Context.default_ctx = mx.gpu(hvd.local_rank()) if mx.test_utils.list_gpus() else mx.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(4)\n",
    "k = GPy.kern.RBF(1, lengthscale=0.1)\n",
    "x = np.random.rand(200,1)\n",
    "y = np.random.multivariate_normal(mean=np.zeros((200,)), cov=k.K(x), size=(1,)).T>0.\n",
    "plt.plot(x[:,0], y[:,0], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D = 10\n",
    "net = nn.HybridSequential(prefix='nn_')\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(D, activation=\"tanh\", flatten=False, in_units=1))\n",
    "    net.add(nn.Dense(D, activation=\"tanh\", flatten=False, in_units=D))\n",
    "    net.add(nn.Dense(2, flatten=False, in_units=D))\n",
    "net.initialize(mx.init.Xavier(magnitude=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxfusion.components.variables.var_trans import PositiveTransformation\n",
    "from mxfusion.inference import VariationalPosteriorForwardSampling\n",
    "from mxfusion.components.functions.operators import broadcast_to\n",
    "from mxfusion.components.distributions import Normal, Categorical\n",
    "from mxfusion import Variable, Model\n",
    "from mxfusion.components.functions import MXFusionGluonFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model()\n",
    "m.N = Variable()\n",
    "m.f = MXFusionGluonFunction(net, num_outputs=1, broadcastable=False)\n",
    "m.x = Variable(shape=(m.N,1))\n",
    "m.r = m.f(m.x)\n",
    "for _,v in m.r.factor.parameters.items():\n",
    "    v.set_prior(Normal(mean=broadcast_to(mx.nd.array([0]), v.shape),\n",
    "                       variance=broadcast_to(mx.nd.array([1.]), v.shape)))\n",
    "m.y = Categorical.define_variable(log_prob=m.r, shape=(m.N,1), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxfusion.inference import DistributedBatchInferenceLoop, create_Gaussian_meanfield, DistributedGradBasedInference, StochasticVariationalInference, MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow distributed training instead of single processor training, the inference class used would be <tt>DistributedGradBasedInference</tt>. The default <tt>grad_loop</tt> of <tt>DistributedGradBasedInference</tt> is <tt>DistributedBatchInferenceLoop</tt>, as opposed to <tt>GradBasedInference</tt>, which is <tt>BatchInferenceLoop</tt>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that currently the code is not running distributed training in Horovod as we are still not running <tt>horovodrun</tt> or <tt>mpirun</tt> command from our system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = [m.y, m.x]\n",
    "q = create_Gaussian_meanfield(model=m, observed=observed)\n",
    "alg = StochasticVariationalInference(num_samples=5, model=m, posterior=q, observed=observed)\n",
    "infr = DistributedGradBasedInference(inference_algorithm=alg, grad_loop=DistributedBatchInferenceLoop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infr.initialize(y=mx.nd.array(y), x=mx.nd.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v_name, v in m.r.factor.parameters.items():\n",
    "    infr.params[q[v].factor.mean] = net.collect_params()[v_name].data()\n",
    "    infr.params[q[v].factor.variance] = mx.nd.ones_like(infr.params[q[v].factor.variance])*1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infr.run(max_iter=500, learning_rate=1e-1, y=mx.nd.array(y), x=mx.nd.array(x), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for uuid, v in infr.inference_algorithm.posterior.variables.items():\n",
    "#     if uuid in infr.params.param_dict:\n",
    "#         print(v.name, infr.params[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.linspace(0,1,100)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infr2 = VariationalPosteriorForwardSampling(10, [m.x], infr, [m.r])\n",
    "res = infr2.run(x=mx.nd.array(xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = res[0].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_mean = yt.mean(0)\n",
    "yt_std = yt.std(0)\n",
    "for i in range(yt.shape[0]):\n",
    "    plt.plot(xt[:,0],1./(1+np.exp(yt[i,:,0]-yt[i,:,1])),'k',alpha=0.2)\n",
    "plt.plot(x[:,0],y[:,0],'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Horovod\n",
    "\n",
    "Currently, the only way to execute Horovod in MXFusion is via <tt>horovodrun</tt> or <tt>mpirun</tt> command from the system. Hence, we can first convert this notebook into Python file then execute the Python file with command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script bnn_classification-distributed.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it on Horovod and allow distributed training, we should run <tt>horovodrun</tt> or <tt>mpirun</tt> from our system while specifying the number of processors. More details about running Horovod can be found [here](https://github.com/horovod/horovod/blob/master/docs/running.rst). A simple way to run it is with the format: <br><tt>horovodrun -np {number of processors} -H localhost:4 python {python file}</tt>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE : Please restart this notebook before executing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun -np 4 -H localhost:4 python bnn_classification-distributed.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
