{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic PCA Tutorial\n",
    "This tutorial will demonstrate Probabilistic PCA, a  factor analysis technique. \n",
    "\n",
    "Maths and notation following [Machine Learning: A Probabilistic Perspective](https://www.amazon.com/gp/product/0262018020).\n",
    "\n",
    "## Installation\n",
    "Follow the instrallation instructions in the [README](../../README.md) file to get setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#\n",
    "#   Licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "#   You may not use this file except in compliance with the License.\n",
    "#   A copy of the License is located at\n",
    "#\n",
    "#       http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#   or in the \"license\" file accompanying this file. This file is distributed\n",
    "#   on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "#   express or implied. See the License for the specific language governing\n",
    "#   permissions and limitations under the License.\n",
    "# ==============================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Probabalistic Modeling Introduction\n",
    "\n",
    "Probabilistic Models can be\n",
    "categorized into directed graphical models (DGM, Bayes Net) and undirected\n",
    "graphical models (UGM). Most popular probabilistic models\n",
    "are DGMs, so MXFusion will only support the definition of\n",
    "DGMs unless there is a strong customer need of UGMs in future.\n",
    "\n",
    "A DGM can be fully defined using 3 basic components: deterministic functions,\n",
    "probabilistic distributions, and random variables. We show the interface for\n",
    "defining a model using each of the three components below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets import the basic libraries we'll need to train our model and visualize some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mxfusion as mf\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "We'll take as our function to learn components of the [log spiral function](https://en.wikipedia.org/wiki/Logarithmic_spiral) because it's 2-dimensional and easy to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_spiral(a,b,t):\n",
    "    x = a * np.exp(b*t) * np.cos(t)\n",
    "    y = a * np.exp(b*t) * np.sin(t)\n",
    "    return np.vstack([x,y]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We parameterize the function with 100 data points and plot the resulting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "D = 100\n",
    "K = 2\n",
    "\n",
    "a = 1\n",
    "b = 0.1\n",
    "t = np.linspace(0,6*np.pi,N)\n",
    "r = log_spiral(a,b,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11a459080>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r[:,0], r[:,1],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now project our $K$ dimensional ```r``` into a high-dimensional $D$ space using a random matrix of random weights $W$. Now that ```r``` is embedded in a $D$ dimensional space the goal of PPCA will be to recover ```r``` in it's original low-dimensional $K$ space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.randn(K,N)\n",
    "x_train = np.dot(r,w) + np.random.randn(N,N) * 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# new_r = pca.fit_transform(x_train)\n",
    "# plt.plot(new_r[:,0], new_r[:,1],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore the higher dimensional data manually by changing ```dim1``` and ```dim2``` in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim1 = 79\n",
    "dim2 = 11\n",
    "plt.scatter(x_train[:,dim1], x_train[:,dim2], color='blue', alpha=0.1)\n",
    "plt.axis([-10, 10, -10, 10])\n",
    "plt.title(\"Simulated data set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MXFusion Model Definition\n",
    "Import MXFusion and MXNet modelling components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxfusion.models import Model\n",
    "import mxnet.gluon.nn as nn\n",
    "from mxfusion.components import Variable\n",
    "from mxfusion.components.variables import PositiveTransformation\n",
    "from mxfusion.components.functions.operators import broadcast_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary data structure in MXFusion is the Model. Models hold ModelComponents, such as Variables, Distributions, and Functions which are the what define a probabilistic model. \n",
    "\n",
    "The model we'll be defining for PPCA is:\n",
    "\n",
    "$p(z)$ ~ $N(\\mathbf{\\mu}, \\mathbf{\\Sigma)}$\n",
    "\n",
    "$p(x | z,\\theta)$ ~ $N(\\mathbf{Wz} + \\mu, \\Psi)$\n",
    "\n",
    "where:\n",
    "\n",
    "$z \\in \\mathbb{R}^{N x K}, \\mathbf{\\mu} \\in \\mathbb{R}^K, \\mathbf{\\Sigma} \\in \\mathbb{R}^{NxKxK}, x \\in \\mathbb{R}^{NxD}$\n",
    "\n",
    "$\\Psi \\in \\mathbb{R}^{NxDxD}, \\Psi = [\\Psi_0, \\dots, \\Psi_N], \\Psi_i = \\sigma^2\\mathbf{I}$\n",
    "\n",
    "$z$ here is our latent variable of interest, $x$ is the observed data, and all other variables are parameters or constants of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create an MXFusion Model object to build our PPCA model on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attach ```Variable``` objects to our model to collect them in a centralized place. Internally, these are organized into a factor graph which is used during Inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.w = Variable(shape=(K,D), initial_value=mx.nd.array(np.random.randn(K,D)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the mean of $x$'s distribution is composed of the dot product of $z$ and $W$, we need to create a dot product function. First we create a dot product function in MXNet and then wrap the function into MXFusion using the MXFusionGluonFunction class. ```m.dot``` can then be called like a normal python function and will apply to the variables it is called on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = nn.HybridLambda(function='dot')\n",
    "m.dot = mf.functions.MXFusionGluonFunction(dot, num_outputs=1, broadcastable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define ```m.z``` which has an identity matrix covariance ```cov``` and zero mean.\n",
    "\n",
    "```m.z``` and ```sigma_2``` are then used to define ```m.x```.\n",
    "\n",
    "Note that both ```sigma_2``` and ```cov``` will be added implicitly into the ```Model``` because they are inputs to ```m.x```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = mx.nd.broadcast_to(mx.nd.expand_dims(mx.nd.array(np.eye(K,K)), 0),shape=(N,K,K))\n",
    "m.z = mf.distributions.MultivariateNormal.define_variable(mean=mx.nd.zeros(shape=(N,K)), covariance=cov, shape=(N,K))\n",
    "m.sigma_2 = Variable(shape=(1,), transformation=PositiveTransformation())\n",
    "m.x = mf.distributions.Normal.define_variable(mean=m.dot(m.z, m.w), variance=broadcast_to(m.sigma_2, (N,D)), shape=(N,D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Definition\n",
    "\n",
    "Now that we have our model, we need to define a posterior with parameters for the inference algorithm to optimize. When constructing a Posterior, we pass in the Model it is defined over and ModelComponent's from the original Model are accessible and visible in the Posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance matrix must continue to be positive definite throughout the optimization process in order to succeed in the Cholesky decomposition when drawing samples or computing the log pdf of ```q.z```. To satisfy this, we pass the covariance matrix parameters through a Gluon function that forces it into a Symmetric matrix for which suitable initialization values should maintain positive definite-ness throughout the optimization procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxfusion.inference import BatchInferenceLoop, GradBasedInference, StochasticVariationalInference\n",
    "class SymmetricMatrix(mx.gluon.HybridBlock):\n",
    "    def hybrid_forward(self, F, x, *args, **kwargs):\n",
    "        return F.sum((F.expand_dims(x, 3)*F.expand_dims(x, 2)), axis=-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this model has an analytical solution, we will run Variational Inference to find the posterior to demonstrate inference in a setting where the answer is known. \n",
    "\n",
    "We place a multivariate normal prior over $z$ because that is $z$'s prior in the model and we don't need to approximate anything in this case. Because the form we're optimizing over is the true model, the optimization is convex and will always converge to the same answer given by classical PCA given enough iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = mf.models.Posterior(m)\n",
    "sym = mf.components.functions.MXFusionGluonFunction(SymmetricMatrix(), num_outputs=1, broadcastable=False)\n",
    "cov = Variable(shape=(N,K,K), initial_value=mx.nd.broadcast_to(mx.nd.expand_dims(mx.nd.array(np.eye(K,K) * 1e-2), 0),shape=(N,K,K)))\n",
    "q.post_cov = sym(cov)\n",
    "q.post_mean = Variable(shape=(N,K), initial_value=mx.nd.array(np.random.randn(N,K)))\n",
    "q.z.set_prior(mf.distributions.MultivariateNormal(mean=q.post_mean, covariance=q.post_cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take our posterior and model, along with an observation pattern (in our case only ```m.x``` is observed) and create an inference algorithm. This inference algorithm is combined with a gradient loop to create the Inference method ```infr```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = [m.x]\n",
    "alg = GeneralizedVariationalInference(num_samples=3, model=m, posterior=q, observed=observed,\n",
    "                                      prior_vars=None, likelihood_vars=[m.z, m.x],\n",
    "                                      alpha=1., gamma=1.)\n",
    "infr = GradBasedInference(inference_algorithm=alg,  grad_loop=BatchInferenceLoop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference method is then initialized with our training data and we run optimiziation for a while until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "infr.initialize(x=mx.nd.array(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /Users/erimeiss/workspace/mxfusion/mxfusion/inference/variational.py(108)compute()\n",
      "-> logL_full = self.model.log_pdf_matrix(F=F, variables=variables)\n",
      "(Pdb) n\n",
      "> /Users/erimeiss/workspace/mxfusion/mxfusion/inference/variational.py(109)compute()\n",
      "-> logL = self.model.log_pdf(F=F, variables=variables)\n",
      "(Pdb) l\n",
      "104  \t        samples = self.posterior.draw_samples(\n",
      "105  \t            F=F, variables=variables, num_samples=self.num_samples)\n",
      "106  \t        variables.update(samples)\n",
      "107  \t        import pdb; pdb.set_trace()\n",
      "108  \t        logL_full = self.model.log_pdf_matrix(F=F, variables=variables)\n",
      "109  ->\t        logL = self.model.log_pdf(F=F, variables=variables)\n",
      "110  \t        logL = logL - self.posterior.log_pdf(F=F, variables=variables)\n",
      "111  \t        return -logL, -logL\n",
      "[EOF]\n",
      "(Pdb) logL_full\n",
      "{'8bb91532_a854_44e5_8e24_7315acfffa6a': \n",
      "[[-2.0818927 -1.996772  -1.9054272 -4.584694  -2.4759064 -2.54461\n",
      "  -2.4268157 -2.5535016 -4.7650576 -2.03614   -3.801666  -3.2661078\n",
      "  -2.316665  -1.8593459 -3.0353293 -1.8701111 -3.74378   -1.951735\n",
      "  -2.4914904 -3.4030967 -1.8812643 -4.1882286 -2.80135   -2.5702085\n",
      "  -1.9211268 -2.05498   -2.2659364 -3.339208  -2.8003116 -2.3162365\n",
      "  -3.0574121 -4.4845195 -2.0315716 -1.9132624 -1.984331  -1.8768833\n",
      "  -2.158994  -4.6362    -1.9788746 -2.8455791 -1.9603672 -2.4348235\n",
      "  -2.7017283 -2.403246  -4.6102734 -2.7247486 -2.1386247 -1.9386125\n",
      "  -3.5236664 -2.0374281 -2.801652  -2.0729566 -4.2070584 -6.2049227\n",
      "  -2.931624  -4.8462915 -3.3742523 -2.0804563 -1.8662752 -2.0633886\n",
      "  -1.838678  -2.877826  -2.13003   -2.92786   -1.9545132 -2.0157897\n",
      "  -2.598486  -2.0679414 -3.170262  -2.3758292 -1.8856015 -3.0452378\n",
      "  -3.3174844 -6.5839767 -2.3934846 -2.9700036 -2.0850677 -2.2300453\n",
      "  -2.6486053 -2.9459488 -2.1190674 -3.56913   -4.1171036 -2.86606\n",
      "  -3.5855844 -2.3905027 -2.324273  -1.9292758 -2.500002  -4.0364847\n",
      "  -2.734923  -1.8467263 -2.2766356 -2.8421688 -2.2584207 -2.0545893\n",
      "  -1.9914378 -2.7287004 -2.3313627 -2.3386679]\n",
      " [-2.0833256 -1.9917127 -1.9040095 -4.6031485 -2.4883852 -2.55439\n",
      "  -2.429071  -2.5830588 -4.7720337 -2.032993  -3.846309  -3.2688437\n",
      "  -2.3122663 -1.8569453 -3.0857966 -1.8737208 -3.7291331 -1.9441226\n",
      "  -2.5065284 -3.3908176 -1.8742956 -4.2385473 -2.8210957 -2.5887241\n",
      "  -1.9194442 -2.057069  -2.2759752 -3.322321  -2.7873704 -2.3116522\n",
      "  -3.057404  -4.5175724 -2.0312607 -1.9046597 -1.9684937 -1.8747532\n",
      "  -2.1365025 -4.632971  -1.9810458 -2.866934  -1.9606918 -2.4451637\n",
      "  -2.6770022 -2.3888774 -4.5921726 -2.6919193 -2.1568887 -1.9387275\n",
      "  -3.5426311 -2.039163  -2.7754993 -2.088739  -4.1838827 -6.237339\n",
      "  -2.9365082 -4.808468  -3.3853767 -2.0651062 -1.8629038 -2.0761795\n",
      "  -1.8385196 -2.897554  -2.1397595 -2.9019432 -1.950779  -2.0187783\n",
      "  -2.5979884 -2.0606077 -3.1855087 -2.3749542 -1.8872496 -3.0187883\n",
      "  -3.3474357 -6.5700607 -2.4004266 -2.962812  -2.0846436 -2.2196643\n",
      "  -2.6433797 -2.948151  -2.1208572 -3.5441065 -4.1578417 -2.8691907\n",
      "  -3.5339189 -2.3920932 -2.3286967 -1.9279165 -2.4940498 -4.02258\n",
      "  -2.7550173 -1.8455538 -2.2865055 -2.8801036 -2.2528007 -2.0475428\n",
      "  -2.008462  -2.7180047 -2.3170347 -2.3171043]\n",
      " [-2.0878336 -2.003085  -1.9102335 -4.5718327 -2.4863813 -2.5660765\n",
      "  -2.417285  -2.5599165 -4.78441   -2.0436687 -3.8175988 -3.257172\n",
      "  -2.3178325 -1.8605207 -3.06393   -1.8697987 -3.7193332 -1.9539402\n",
      "  -2.4975932 -3.4362257 -1.8752847 -4.214822  -2.8281827 -2.5916944\n",
      "  -1.9185343 -2.051186  -2.2777495 -3.367982  -2.779972  -2.3096216\n",
      "  -3.0736418 -4.4848146 -2.0401766 -1.9134126 -1.9736575 -1.880177\n",
      "  -2.152865  -4.6245832 -1.9784185 -2.861621  -1.9652598 -2.4516168\n",
      "  -2.6671643 -2.39369   -4.609269  -2.6974463 -2.1550865 -1.9385873\n",
      "  -3.5241098 -2.0358512 -2.7874217 -2.0709026 -4.294016  -6.2941694\n",
      "  -2.9398339 -4.8347344 -3.3803675 -2.080617  -1.861955  -2.0688605\n",
      "  -1.8390008 -2.9083166 -2.1327302 -2.896507  -1.9482428 -2.0190728\n",
      "  -2.5925004 -2.0555356 -3.176008  -2.3678598 -1.8725597 -3.0032406\n",
      "  -3.3242757 -6.5638494 -2.3978002 -2.970449  -2.071573  -2.2219296\n",
      "  -2.6675103 -2.940244  -2.1275349 -3.5529408 -4.1331234 -2.8960583\n",
      "  -3.5582354 -2.3802679 -2.3242908 -1.9336112 -2.4866314 -4.012494\n",
      "  -2.722142  -1.846865  -2.2573395 -2.848733  -2.2533073 -2.04384\n",
      "  -1.9951715 -2.7327108 -2.3415494 -2.324187 ]]\n",
      "<NDArray 3x100 @cpu(0)>, 'd531f2d6_9afa_4841_bce6_a0aebaa554ea': \n",
      "[[[  -0.86977017   -0.8232521    -1.359257   ...   -0.93997806\n",
      "     -2.106068     -1.0447481 ]\n",
      "  [  -0.73838013   -1.4720542    -0.7666826  ...   -0.95237786\n",
      "     -4.4421988    -0.7420455 ]\n",
      "  [  -0.74295527   -0.79841524   -1.959414   ...   -1.1222692\n",
      "     -2.5343804    -0.74047226]\n",
      "  ...\n",
      "  [  -8.506653     -2.1359963    -3.6854272  ...   -0.7911041\n",
      "   -103.353714    -23.41366   ]\n",
      "  [  -4.7425456    -3.5597997    -1.1291771  ...   -4.593198\n",
      "   -107.810455    -19.37969   ]\n",
      "  [  -3.583242     -1.1243218    -6.4741864  ...   -4.4360332\n",
      "   -113.19419      -6.374235  ]]\n",
      "\n",
      " [[  -0.8700429    -0.8172035    -1.3658855  ...   -0.95842\n",
      "     -2.0615704    -1.0622417 ]\n",
      "  [  -0.738469     -1.4737018    -0.77123344 ...   -0.9724716\n",
      "     -4.340512     -0.74462074]\n",
      "  [  -0.7429571    -0.7892996    -1.9498763  ...   -1.0841165\n",
      "     -2.6115546    -0.74337727]\n",
      "  ...\n",
      "  [  -8.46513      -2.0709052    -3.7871232  ...   -0.79547715\n",
      "   -103.946625    -23.297499  ]\n",
      "  [  -4.756145     -3.52029      -1.1123939  ...   -4.615525\n",
      "   -107.5085      -19.437216  ]\n",
      "  [  -3.570478     -1.1502327    -6.4098496  ...   -4.457997\n",
      "   -113.30915      -6.3825884 ]]\n",
      "\n",
      " [[  -0.8709425    -0.82455635   -1.370671   ...   -0.947442\n",
      "     -2.078298     -1.052981  ]\n",
      "  [  -0.7383581    -1.5085864    -0.7671069  ...   -0.9801539\n",
      "     -4.349577     -0.745226  ]\n",
      "  [  -0.74337786   -0.7873076    -1.9791082  ...   -1.1014988\n",
      "     -2.5532508    -0.74164546]\n",
      "  ...\n",
      "  [  -8.499114     -2.1309385    -3.706019   ...   -0.7941194\n",
      "   -103.54849     -23.357922  ]\n",
      "  [  -4.742433     -3.6044655    -1.1255943  ...   -4.678094\n",
      "   -107.41057     -19.521479  ]\n",
      "  [  -3.573718     -1.1408324    -6.4238267  ...   -4.438813\n",
      "   -113.34763      -6.3676724 ]]]\n",
      "<NDArray 3x100x100 @cpu(0)>}\n",
      "(Pdb) self\n",
      "<mxfusion.inference.variational.StochasticVariationalInference object at 0x11c6885c0>\n",
      "(Pdb) self.model\n",
      "Model (9c757)\n",
      "Variable (dcc12) = BroadcastToOperator(data=Variable sigma_2 (f693e))\n",
      "Variable z (2ed33) ~ MultivariateNormal(mean=Variable (a61fd), covariance=Variable (b9f99))\n",
      "Variable (c6739) = GluonFunctionEvaluation(hybridlambda0_input_0=Variable z (2ed33), hybridlambda0_input_1=Variable w (467bd))\n",
      "Variable x (02444) ~ Normal(mean=Variable (c6739), variance=Variable (dcc12))\n",
      "(Pdb) self.model['d531f2d6_9afa_4841_bce6_a0aebaa554ea']\n",
      "Normal(mean=Variable (c6739), variance=Variable (dcc12))\n",
      "(Pdb) logL_full['d531f2d6_9afa_4841_bce6_a0aebaa554ea'].shape\n",
      "(3, 100, 100)\n",
      "(Pdb)  self.num_samples\n",
      "3\n",
      "(Pdb) self.model['8bb91532_a854_44e5_8e24_7315acfffa6a']\n",
      "MultivariateNormal(mean=Variable (a61fd), covariance=Variable (b9f99))\n",
      "--KeyboardInterrupt--\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1bfe1c43a321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/mxfusion/mxfusion/inference/grad_based_inference.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, optimizer, learning_rate, max_iter, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0minfr_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmxnet_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 learning_rate=learning_rate, max_iter=max_iter, verbose=verbose, logger=self._logger)\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGradTransferInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradBasedInference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/mxfusion/mxfusion/inference/batch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, infr_executor, data, param_dict, ctx, optimizer, learning_rate, max_iter, n_prints, verbose, logger)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_for_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfr_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mloss_for_gradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/mxfusion/mxfusion/inference/inference_alg.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, x, *args, **kw)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0madd_sample_dimension_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0madd_sample_dimension_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infr_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m# An inference algorithm may directly set the value of a parameter instead of computing its gradient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/mxfusion/mxfusion/inference/variational.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, F, variables)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mlogL_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_pdf_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mlogL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mlogL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/mxfusion/mxfusion/inference/variational.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, F, variables)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mlogL_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_pdf_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mlogL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mlogL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "infr.run(max_iter=1000, learning_rate=1e-2, x=mx.nd.array(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.x.factor.log_pdf_impl(mean=mx.nd.array([1,2]), variance=mx.nd.array([1,2]), random_variable=mx.nd.array([1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training completes, we retrieve the posterior mean (our trained representation for $\\mathbf{Wz} + \\mu$) from the inference method and plot it. \n",
    "As shown, the plot recovers (up to rotation) the original 2D data quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_z_mean = infr.params[q.z.factor.mean].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(post_z_mean[:,0], post_z_mean[:,1],'.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
