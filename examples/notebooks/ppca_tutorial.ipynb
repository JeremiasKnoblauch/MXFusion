{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic PCA Tutorial\n",
    "This tutorial will demonstrate Probabilistic PCA, a  factor analysis technique. \n",
    "\n",
    "Maths and notation following [Machine Learning: A Probabilistic Perspective](https://www.amazon.com/gp/product/0262018020).\n",
    "\n",
    "## Installation\n",
    "Follow the instrallation instructions in the [README](../../README.md) file to get setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#\n",
    "#   Licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "#   You may not use this file except in compliance with the License.\n",
    "#   A copy of the License is located at\n",
    "#\n",
    "#       http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#   or in the \"license\" file accompanying this file. This file is distributed\n",
    "#   on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "#   express or implied. See the License for the specific language governing\n",
    "#   permissions and limitations under the License.\n",
    "# ==============================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Probabalistic Modeling Introduction\n",
    "\n",
    "Probabilistic Models can be\n",
    "categorized into directed graphical models (DGM, Bayes Net) and undirected\n",
    "graphical models (UGM). Most popular probabilistic models\n",
    "are DGMs, so MXFusion will only support the definition of\n",
    "DGMs unless there is a strong customer need of UGMs in future.\n",
    "\n",
    "A DGM can be fully defined using 3 basic components: deterministic functions,\n",
    "probabilistic distributions, and random variables. We show the interface for\n",
    "defining a model using each of the three components below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets import the basic libraries we'll need to train our model and visualize some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mxfusion as mf\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "We'll take as our function to learn components of the [log spiral function](https://en.wikipedia.org/wiki/Logarithmic_spiral) because it's 2-dimensional and easy to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_spiral(a,b,t):\n",
    "    x = a * np.exp(b*t) * np.cos(t)\n",
    "    y = a * np.exp(b*t) * np.sin(t)\n",
    "    return np.vstack([x,y]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We parameterize the function with 100 data points and plot the resulting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "D = 100\n",
    "K = 2\n",
    "\n",
    "a = 1\n",
    "b = 0.1\n",
    "t = np.linspace(0,6*np.pi,N)\n",
    "r = log_spiral(a,b,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11efdfcf8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r[:,0], r[:,1],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now project our $K$ dimensional ```r``` into a high-dimensional $D$ space using a random matrix of random weights $W$. Now that ```r``` is embedded in a $D$ dimensional space the goal of PPCA will be to recover ```r``` in it's original low-dimensional $K$ space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.randn(K,N)\n",
    "x_train = np.dot(r,w) + np.random.randn(N,N) * 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# new_r = pca.fit_transform(x_train)\n",
    "# plt.plot(new_r[:,0], new_r[:,1],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore the higher dimensional data manually by changing ```dim1``` and ```dim2``` in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim1 = 79\n",
    "dim2 = 11\n",
    "plt.scatter(x_train[:,dim1], x_train[:,dim2], color='blue', alpha=0.1)\n",
    "plt.axis([-10, 10, -10, 10])\n",
    "plt.title(\"Simulated data set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MXFusion Model Definition\n",
    "Import MXFusion and MXNet modelling components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxfusion.models import Model\n",
    "import mxnet.gluon.nn as nn\n",
    "from mxfusion.components import Variable\n",
    "from mxfusion.components.variables import PositiveTransformation\n",
    "from mxfusion.components.functions.operators import broadcast_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary data structure in MXFusion is the Model. Models hold ModelComponents, such as Variables, Distributions, and Functions which are the what define a probabilistic model. \n",
    "\n",
    "The model we'll be defining for PPCA is:\n",
    "\n",
    "$p(z)$ ~ $N(\\mathbf{\\mu}, \\mathbf{\\Sigma)}$\n",
    "\n",
    "$p(x | z,\\theta)$ ~ $N(\\mathbf{Wz} + \\mu, \\Psi)$\n",
    "\n",
    "where:\n",
    "\n",
    "$z \\in \\mathbb{R}^{N x K}, \\mathbf{\\mu} \\in \\mathbb{R}^K, \\mathbf{\\Sigma} \\in \\mathbb{R}^{NxKxK}, x \\in \\mathbb{R}^{NxD}$\n",
    "\n",
    "$\\Psi \\in \\mathbb{R}^{NxDxD}, \\Psi = [\\Psi_0, \\dots, \\Psi_N], \\Psi_i = \\sigma^2\\mathbf{I}$\n",
    "\n",
    "$z$ here is our latent variable of interest, $x$ is the observed data, and all other variables are parameters or constants of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create an MXFusion Model object to build our PPCA model on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attach ```Variable``` objects to our model to collect them in a centralized place. Internally, these are organized into a factor graph which is used during Inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.w = Variable(shape=(K,D), initial_value=mx.nd.array(np.random.randn(K,D)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the mean of $x$'s distribution is composed of the dot product of $z$ and $W$, we need to create a dot product function. First we create a dot product function in MXNet and then wrap the function into MXFusion using the MXFusionGluonFunction class. ```m.dot``` can then be called like a normal python function and will apply to the variables it is called on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = nn.HybridLambda(function='dot')\n",
    "m.dot = mf.functions.MXFusionGluonFunction(dot, num_outputs=1, broadcastable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define ```m.z``` which has an identity matrix covariance ```cov``` and zero mean.\n",
    "\n",
    "```m.z``` and ```sigma_2``` are then used to define ```m.x```.\n",
    "\n",
    "Note that both ```sigma_2``` and ```cov``` will be added implicitly into the ```Model``` because they are inputs to ```m.x```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = mx.nd.broadcast_to(mx.nd.expand_dims(mx.nd.array(np.eye(K,K)), 0),shape=(N,K,K))\n",
    "m.z = mf.distributions.MultivariateNormal.define_variable(mean=mx.nd.zeros(shape=(N,K)), covariance=cov, shape=(N,K))\n",
    "m.sigma_2 = Variable(shape=(1,), transformation=PositiveTransformation())\n",
    "m.x = mf.distributions.Normal.define_variable(mean=m.dot(m.z, m.w), variance=broadcast_to(m.sigma_2, (N,D)), shape=(N,D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Definition\n",
    "\n",
    "Now that we have our model, we need to define a posterior with parameters for the inference algorithm to optimize. When constructing a Posterior, we pass in the Model it is defined over and ModelComponent's from the original Model are accessible and visible in the Posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance matrix must continue to be positive definite throughout the optimization process in order to succeed in the Cholesky decomposition when drawing samples or computing the log pdf of ```q.z```. To satisfy this, we pass the covariance matrix parameters through a Gluon function that forces it into a Symmetric matrix for which suitable initialization values should maintain positive definite-ness throughout the optimization procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxfusion.inference import BatchInferenceLoop, GradBasedInference, GeneralizedVariationalInference, StochasticVariationalInference, RenyiAlpha, GammaLoss\n",
    "class SymmetricMatrix(mx.gluon.HybridBlock):\n",
    "    def hybrid_forward(self, F, x, *args, **kwargs):\n",
    "        return F.sum((F.expand_dims(x, 3)*F.expand_dims(x, 2)), axis=-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this model has an analytical solution, we will run Variational Inference to find the posterior to demonstrate inference in a setting where the answer is known. \n",
    "\n",
    "We place a multivariate normal prior over $z$ because that is $z$'s prior in the model and we don't need to approximate anything in this case. Because the form we're optimizing over is the true model, the optimization is convex and will always converge to the same answer given by classical PCA given enough iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = mf.models.Posterior(m)\n",
    "sym = mf.components.functions.MXFusionGluonFunction(SymmetricMatrix(), num_outputs=1, broadcastable=False)\n",
    "cov = Variable(shape=(N,K,K), initial_value=mx.nd.broadcast_to(mx.nd.expand_dims(mx.nd.array(np.eye(K,K) * 1e-2), 0),shape=(N,K,K)))\n",
    "q.post_cov = sym(cov)\n",
    "q.post_mean = Variable(shape=(N,K), initial_value=mx.nd.array(np.random.randn(N,K)))\n",
    "q.z.set_prior(mf.distributions.MultivariateNormal(mean=q.post_mean, covariance=q.post_cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take our posterior and model, along with an observation pattern (in our case only ```m.x``` is observed) and create an inference algorithm. This inference algorithm is combined with a gradient loop to create the Inference method ```infr```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = [m.x]\n",
    "loss_function = GammaLoss(2.)\n",
    "divergence = RenyiAlpha(3.)\n",
    "\n",
    "alg = GeneralizedVariationalInference(num_samples=3, model=m, posterior=q, observed=observed,\n",
    "                                      prior_vars=None, likelihood_vars=[m.z, m.x],\n",
    "                                      divergence=divergence, loss_function=loss_function, data_size=len(x_train))\n",
    "# alg = StochasticVariationalInference(num_samples=3, model=m, posterior=q, observed=observed)\n",
    "\n",
    "infr = GradBasedInference(inference_algorithm=alg,  grad_loop=BatchInferenceLoop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference method is then initialized with our training data and we run optimiziation for a while until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "infr.initialize(x=mx.nd.array(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_likelihood: \n",
      "[[-1277.4371  -1082.6447  -1002.2145  -1134.3063  -1003.9883  -1002.47314\n",
      "   -990.05396 -1202.0746  -1057.0712  -1703.5632  -1022.7495  -1063.96\n",
      "  -1049.139   -1151.3408  -1150.3212  -1086.7933  -1340.5487  -1066.0568\n",
      "  -1133.6605  -1136.6396  -1058.3912  -1148.6455  -1105.5348  -1407.1499\n",
      "  -1107.7625  -1472.6151  -1250.0223  -1125.21    -1282.2968  -1371.9141\n",
      "  -1239.3905  -1196.9482  -1292.449   -1512.2828  -1218.9917  -1236.5883\n",
      "  -1709.9939  -1248.1558  -1434.375   -1286.1304  -1509.6173  -1272.4373\n",
      "  -1317.8037  -1425.4033  -1440.1798  -1402.4062  -1810.1855  -1522.1877\n",
      "  -1533.301   -1459.1874  -1538.8479  -1472.596   -1542.9154  -1500.9316\n",
      "  -1526.8823  -1696.9507  -1960.3506  -1722.5332  -1707.3888  -1645.7952\n",
      "  -1750.0686  -1836.102   -1957.8096  -1973.3069  -2016.5205  -1946.5869\n",
      "  -1952.8123  -2165.222   -1947.7173  -1934.1426  -2017.4502  -2053.6057\n",
      "  -1937.4556  -2151.9966  -2143.4192  -2158.6677  -2562.7324  -2551.9924\n",
      "  -2697.9949  -2658.3728  -2903.3894  -3185.9177  -3162.0872  -3154.1235\n",
      "  -2854.0032  -2916.9517  -2828.9739  -2837.4028  -3256.8567  -3017.9465\n",
      "  -3306.3796  -3272.8633  -3420.866   -3666.9001  -3871.076   -4132.315\n",
      "  -4458.6646  -4596.9297  -4555.486   -4613.648  ]\n",
      " [-1274.4706  -1078.7087  -1003.38446 -1135.9365  -1003.24646 -1001.7573\n",
      "   -990.1559  -1196.4131  -1056.6517  -1697.1636  -1021.6786  -1063.7168\n",
      "  -1050.2257  -1147.9414  -1147.2528  -1088.001   -1340.019   -1065.4014\n",
      "  -1134.9518  -1135.3883  -1058.5386  -1151.2267  -1105.1581  -1406.4869\n",
      "  -1108.2952  -1472.7722  -1247.7     -1125.9971  -1279.886   -1372.344\n",
      "  -1240.384   -1197.6838  -1295.4756  -1516.9023  -1221.6862  -1236.1324\n",
      "  -1705.7241  -1248.8081  -1433.1082  -1288.4624  -1506.4697  -1272.9856\n",
      "  -1320.3429  -1428.4629  -1439.9702  -1400.0264  -1802.5525  -1524.2888\n",
      "  -1535.0981  -1459.5544  -1535.6725  -1473.6777  -1540.2169  -1501.6309\n",
      "  -1527.5414  -1692.8357  -1958.4404  -1735.8975  -1710.9376  -1645.869\n",
      "  -1749.9196  -1838.4197  -1956.1206  -1972.7761  -2020.2549  -1947.1174\n",
      "  -1952.7632  -2167.8792  -1947.2661  -1934.0725  -2020.5554  -2050.373\n",
      "  -1936.8286  -2150.246   -2143.1067  -2158.792   -2564.547   -2553.7341\n",
      "  -2697.124   -2658.5034  -2903.5398  -3183.9844  -3165.9553  -3155.2725\n",
      "  -2854.7954  -2917.7024  -2828.962   -2836.0232  -3263.9812  -3014.9775\n",
      "  -3310.7544  -3271.5955  -3420.82    -3667.8613  -3872.423   -4126.7817\n",
      "  -4466.4473  -4598.251   -4553.1587  -4611.024  ]\n",
      " [-1274.3344  -1078.7822  -1002.05615 -1139.229   -1002.2824  -1003.44226\n",
      "   -989.81226 -1199.3064  -1057.4374  -1700.2886  -1022.053   -1061.1028\n",
      "  -1050.4473  -1151.1725  -1147.0142  -1088.3167  -1342.3176  -1066.1084\n",
      "  -1134.2631  -1139.9303  -1058.5406  -1149.8402  -1106.7086  -1411.5938\n",
      "  -1108.2524  -1469.1084  -1244.9271  -1124.6193  -1277.2336  -1371.4324\n",
      "  -1241.4702  -1197.293   -1296.2637  -1509.0325  -1220.318   -1237.5839\n",
      "  -1709.9602  -1248.0719  -1434.1045  -1288.5645  -1504.1011  -1273.5902\n",
      "  -1320.4034  -1427.3015  -1438.8896  -1400.9031  -1809.0339  -1522.5933\n",
      "  -1534.1111  -1459.2344  -1535.0083  -1472.5686  -1548.0728  -1500.3711\n",
      "  -1526.4795  -1695.4012  -1959.3074  -1727.6802  -1712.0481  -1646.8452\n",
      "  -1750.1333  -1837.205   -1956.815   -1973.2422  -2020.6758  -1947.3477\n",
      "  -1952.908   -2170.2744  -1947.6685  -1933.4985  -2017.2664  -2048.5488\n",
      "  -1937.0884  -2150.0474  -2143.0378  -2159.5686  -2558.8542  -2554.7627\n",
      "  -2699.9631  -2657.9072  -2906.161   -3184.9045  -3164.711   -3150.791\n",
      "  -2854.4907  -2916.641   -2827.99    -2837.228   -3265.278   -3017.5222\n",
      "  -3304.9045  -3273.3276  -3417.1934  -3671.125   -3871.4844  -4127.558\n",
      "  -4460.4595  -4598.3354  -4554.1367  -4611.945  ]]\n",
      "<NDArray 3x100 @cpu(0)>\n",
      "total_prior_loss: \n",
      "[-109033.38 -109039.14 -109038.36]\n",
      "<NDArray 3 @cpu(0)>\n",
      "total_posterior_loss: \n",
      "[626.33044 647.1016  626.27203]\n",
      "<NDArray 3 @cpu(0)>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "compute_loss() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1bfe1c43a321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/mxfusion/mxfusion/inference/grad_based_inference.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, optimizer, learning_rate, max_iter, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0minfr_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmxnet_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 learning_rate=learning_rate, max_iter=max_iter, verbose=verbose, logger=self._logger)\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGradTransferInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradBasedInference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/mxfusion/mxfusion/inference/batch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, infr_executor, data, param_dict, ctx, optimizer, learning_rate, max_iter, n_prints, verbose, logger)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_for_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfr_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mloss_for_gradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/mxfusion/mxfusion/inference/inference_alg.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, x, *args, **kw)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0madd_sample_dimension_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0madd_sample_dimension_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infr_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m# An inference algorithm may directly set the value of a parameter instead of computing its gradient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/mxfusion/mxfusion/inference/gvi.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, F, variables)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"total_posterior_loss: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_posterior_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mlogL_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Step 2: Divergence. Do inside self.divergence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_loss() takes 3 positional arguments but 4 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/erimeiss/workspace/mxfusion/mxfusion/inference/gvi.py\u001b[0m(72)\u001b[0;36mcompute\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     70 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"total_posterior_loss: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_posterior_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 72 \u001b[0;31m        \u001b[0mlogL_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     73 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m        \u001b[0;31m# Step 2: Divergence. Do inside self.divergence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "infr.run(max_iter=1000, learning_rate=1e-2, x=mx.nd.array(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.x.factor.log_pdf_impl(mean=mx.nd.array([1,2]), variance=mx.nd.array([1,2]), random_variable=mx.nd.array([1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training completes, we retrieve the posterior mean (our trained representation for $\\mathbf{Wz} + \\mu$) from the inference method and plot it. \n",
    "As shown, the plot recovers (up to rotation) the original 2D data quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_z_mean = infr.params[q.z.factor.mean].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mx.nd.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(post_z_mean[:,0], post_z_mean[:,1],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
